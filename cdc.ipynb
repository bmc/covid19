{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Data Analyses using CDC Data\n",
    "\n",
    "Note: The most up-to-date version of this notebook can be found in GitHub repository [bmc/covid19][].\n",
    "\n",
    "The primary data source for this notebook is the Centers for Disease Control and Prevention's\n",
    "[Provisional Death Counts for Coronavirus Disease](https://www.cdc.gov/nchs/nvss/vsrr/covid19/index.htm).\n",
    "\n",
    "This data source is less rich and appears to be less timely than either the Johns Hopkins or the New York\n",
    "Times data.\n",
    "\n",
    "For additional data sources used, see [the README](https://github.com/bmc/covid19/blob/master/README.md)\n",
    "in [bmc/covid19].\n",
    "\n",
    "## Approach\n",
    "\n",
    "This notebook loads the CDC CSV file into a [Pandas](https://pandas.pydata.org/) DataFrame. It\n",
    "then manipulates, queries, and plots the DataFrame.\n",
    "\n",
    "[**I don't want to look at code. Take me to the plots!**](#Plots)\n",
    "\n",
    "\n",
    "[bmc/covid19]: https://github.com/bmc/covid19/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python 3.8.4\n",
      "Using matplotlib 3.2.2\n",
      "Using Pandas 1.0.5\n",
      "Last run on 2020-08-27 at 16:08:39 UTC\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as p\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, date, timezone\n",
    "from enum import Enum\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from lib.common import *\n",
    "from lib.plot import *\n",
    "\n",
    "print(f\"Using Python {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "print(f\"Using matplotlib {matplotlib.__version__}\")\n",
    "print(f\"Using Pandas {pd.__version__}\")\n",
    "now = datetime.now(timezone.utc)\n",
    "print(f\"Last run on {now.strftime('%Y-%m-%d')} at {now.strftime('%H:%M:%S %Z')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDC_DATA_PATH = 'data/cdc/Provisional_COVID-19_Death_Counts_by_Week_Ending_Date_and_State.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(IMAGES_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preload the data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334,351,340\n"
     ]
    }
   ],
   "source": [
    "populations = load_united_states_population_data()\n",
    "print(f\"{populations['United States']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTING_DATE = datetime(year=2020, month=4, day=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data as of,Start week,End Week,Group,State,Indicator,COVID-19 Deaths,Total Deaths,Percent of Expected Deaths,Pneumonia Deaths,Pneumonia and COVID-19 Deaths,Influenza Deaths,\"Pneumonia, Influenza, or COVID-19 Deaths\",Footnote\n",
      "08/27/2020,02/03/0020,02/03/0020,By week,United States,Week-ending,0,58535,0.99,3790,0,479,4269,\n",
      "08/27/2020,02/10/0020,02/10/0020,By week,United States,Week-ending,1,59268,0.99,3795,0,520,4316,\n",
      "08/27/2020,02/17/0020,02/17/0020,By week,United States,Week-ending,0,58672,1,3822,0,555,4377,\n",
      "08/27/2020,02/24/0020,02/24/0020,By week,United States,Week-ending,5,58709,1.01,3693,1,564,4261,\n",
      "08/27/2020,03/02/0020,03/02/0020,By week,United States,Week-ending,9,59131,1.03,3817,5,654,4475,\n",
      "08/27/2020,03/09/0020,03/09/0020,By week,United States,Week-ending,35,59470,1.03,3952,17,631,4600,\n",
      "08/27/2020,03/16/0020,03/16/0020,By week,United States,Week-ending,52,58180,1.02,3941,27,619,4584,\n",
      "08/27/2020,03/23/0020,03/23/0020,By week,United States,Week-ending,571,58833,1.04,4520,252,560,5392,\n",
      "08/27/2020,03/30/0020,03/30/0020,By week,United States,Week-ending,3152,62798,1.12,6161,1425,441,8279,\n"
     ]
    }
   ],
   "source": [
    "%head $CDC_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data.\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(CDC_DATA_PATH)\n",
    "    date_fmt = '%m/%d/%Y'\n",
    "    for col in ('Data as of', 'Start week', 'End Week'):\n",
    "        df[col] = pd.to_datetime(df[col], format=date_fmt)\n",
    "\n",
    "    df['month_day'] = df.apply(lambda r: r['Start week'].date().strftime(\"%m/%d\"), axis=1)\n",
    "\n",
    "    columns_to_rename = {\n",
    "        'Data as of':      'data_as_of',\n",
    "        'Start week':      'start_week',\n",
    "        'End Week':        'end_week',\n",
    "        'Group':           'group',\n",
    "        'State':           'state',\n",
    "        'Indicator':       'indicator',\n",
    "        'COVID-19 Deaths': 'week_deaths',\n",
    "        'Total Deaths':    'total_deaths',\n",
    "    }\n",
    "\n",
    "    df2 = df.rename(columns=columns_to_rename)\n",
    "    df2['week_deaths'] = df2['week_deaths'].fillna(0)\n",
    "    df2['total_deaths'] = df2['total_deaths'].fillna(0)\n",
    "    df3 = df2.loc[df2.start_week >= STARTING_DATE]\n",
    "    desired_columns = list(columns_to_rename.values()) + ['month_day']\n",
    "    return df3[desired_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfBoundsDatetime",
     "evalue": "Out of bounds nanosecond timestamp: 20-02-03 00:00:00",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-625ea9f31ba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-638bb80cc905>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdate_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%m/%d/%Y'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Data as of'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Start week'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'End Week'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_fmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month_day'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Start week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%m/%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0munique_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mcache_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                     result, timezones = array_strptime(\n\u001b[0m\u001b[1;32m    400\u001b[0m                         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                     )\n",
      "\u001b[0;32mpandas/_libs/tslibs/strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/np_datetime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 20-02-03 00:00:00"
     ]
    }
   ],
   "source": [
    "df = load_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_death_counts(df, state='United States', trim_final_week=True):\n",
    "    \"\"\"\n",
    "    Extract weekly death counts for a particular state or\n",
    "    for the United States as a whole.\n",
    "\n",
    "    Returns a new DataFrame with only data for the specified state,\n",
    "    with the 'start_week', 'month_day', 'state', and 'week_deaths'\n",
    "    columns, as well as a 'cumulative_deaths' column that captures\n",
    "    cumulative deaths as of a given week.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    df              - Pandas DataFrame containing the CDC data,\n",
    "                      as loaded by load_data()\n",
    "    state           - The state for which data is to be returned.\n",
    "    trim_final_week - True to trim the final week; False otherwise.\n",
    "\n",
    "    NOTE: The final week of the CDC data is automatically trimmed\n",
    "    (unless trim_final_week is set to False), because experience\n",
    "    shows that it generally represents partial data, which skews the\n",
    "    graphs.\n",
    "    \"\"\"\n",
    "    df2 = df.loc[df.state == state].sort_values('month_day', inplace=False)\n",
    "    if trim_final_week:\n",
    "        df2.drop(df2.tail(1).index, inplace=True)\n",
    "\n",
    "    df2['cumulative_deaths'] = df2.week_deaths.cumsum()\n",
    "    return df2[['start_week', 'month_day', 'state', 'week_deaths',\n",
    "                'cumulative_deaths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotType(Enum):\n",
    "    WEEKLY_DEATHS = 0\n",
    "    CUMULATIVE_DEATHS = 1\n",
    "\n",
    "    @classmethod\n",
    "    def all(cls):\n",
    "        return set([v for v in PlotType])\n",
    "\n",
    "\n",
    "PLOT_TYPE_COLORS = {\n",
    "    PlotType.WEEKLY_DEATHS: 'orange',\n",
    "    PlotType.CUMULATIVE_DEATHS: 'red'\n",
    "}\n",
    "\n",
    "PLOT_TYPE_COLUMNS = {\n",
    "    PlotType.WEEKLY_DEATHS: 'week_deaths',\n",
    "    PlotType.CUMULATIVE_DEATHS: 'cumulative_deaths'  \n",
    "}\n",
    "\n",
    "PLOT_TYPE_LABELS = {\n",
    "    PlotType.WEEKLY_DEATHS: 'weekly deaths',\n",
    "    PlotType.CUMULATIVE_DEATHS: 'cumulative deaths'   \n",
    "}\n",
    "\n",
    "def plot_deaths_for_one(df, state, plot_types={PlotType.CUMULATIVE_DEATHS},\n",
    "                        image_file=None, figsize=(20, 12), legend_loc='upper center',\n",
    "                        marker=False, trim_final_week=True):\n",
    "    \"\"\"\n",
    "    Extract weekly death counts for a particular state or\n",
    "    for the United States as a whole, via a call to get_death_counts(),\n",
    "    and plot the data.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    df              - Pandas DataFrame containing the CDC data,\n",
    "                      as loaded by load_data()\n",
    "    state           - The state for which data is to be plotted.\n",
    "    plot_types      - Whether to plot cumulative deaths, weekly deaths,\n",
    "                      or both.\n",
    "    image_file      - Optional name of file to which to save the plot.\n",
    "    figsize         - The desired size of the plot.\n",
    "    legend_loc      - Desired location of the legend. The legend is\n",
    "                      only displayed if more than one plot type is\n",
    "                      set.\n",
    "    marker          - True to display a marker for each data point.\n",
    "                      False to suppress the marker.\n",
    "    trim_final_week - True to trim the final week; False otherwise.\n",
    "\n",
    "    NOTE: The final week of the CDC data is automatically trimmed\n",
    "    (unless trim_final_week is set to False), because experience\n",
    "    shows that it generally represents partial data, which skews the\n",
    "    graphs.\n",
    "    \"\"\"\n",
    "    df2 = get_death_counts(df, state, trim_final_week)\n",
    "    fig, ax = p.subplots(figsize=figsize)\n",
    "    legend_labels = []\n",
    "    for m in PlotType:\n",
    "        if m in plot_types:\n",
    "            column = PLOT_TYPE_COLUMNS[m]\n",
    "            legend_labels.append(PLOT_TYPE_LABELS[m])\n",
    "            # No grouping is necessary here, because there's\n",
    "            # only one row per week in the CDC data. Just select\n",
    "            # the columns we want to plot.\n",
    "            df2.plot(x='month_day', y=column,\n",
    "                     ax=ax, figsize=figsize, \n",
    "                     color=PLOT_TYPE_COLORS[m],\n",
    "                     marker=('s' if marker else None))\n",
    "\n",
    "    date_fmt = '%b %d'\n",
    "    start_date = df2.start_week.min().strftime(date_fmt)\n",
    "    end_date = df2.start_week.max().strftime(date_fmt)\n",
    "\n",
    "    text_lines = [f\"{state} deaths from {start_date} to {end_date}\"]\n",
    "    if PlotType.CUMULATIVE_DEATHS in plot_types:\n",
    "        total = int(round(df2.cumulative_deaths.max()))\n",
    "        text_lines.append(f'\\nTotal deaths: {total:,}')\n",
    "\n",
    "    textbox(ax, 0.01, 0.98, '\\n'.join(text_lines))\n",
    "\n",
    "    if len(plot_types) > 1:\n",
    "        ax.legend(legend_labels, loc=legend_loc)\n",
    "\n",
    "    ax.set_ylabel(f\"{state} deaths\")\n",
    "    ax.set_xlabel(\"Week\\n\\n(Source: CDC)\")\n",
    "    \n",
    "    if image_file is not None:\n",
    "        fig.savefig(os.path.join(IMAGES_PATH, image_file))\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "### US deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_deaths_for_one(df, 'United States', plot_types=PlotType.all(), marker=True,\n",
    "                              image_file='cdc-us-deaths.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pennsylvania (my home state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_deaths_for_one(df, 'Pennsylvania', plot_types=PlotType.all(), marker=True,\n",
    "                              image_file='cdc-pa-deaths.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_deaths_for_one(df, 'California', plot_types=PlotType.all(), marker=True,\n",
    "                              image_file='cdc-ca-deaths.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing deaths in groups of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_deaths_for_many(df, states, plot_type, image_file=None, \n",
    "                         per_n=1, populations=None,\n",
    "                         figsize=(20, 12), legend_loc='best',\n",
    "                         marker=False, trim_final_week=True):\n",
    "    \"\"\"\n",
    "    Extract weekly death counts for multiple states (or the U.S.)\n",
    "    via calls to get_death_counts(), and plot the data.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    df              - Pandas DataFrame containing the CDC data,\n",
    "                      as loaded by load_data()\n",
    "    states          - The state for which data is to be plotted.\n",
    "    plot_types      - Whether to plot cumulative deaths or weekly deaths.\n",
    "    image_file_name - Optional name of file to which to save the plot.\n",
    "    per_n           - If set to 1, plot the data as is. Otherwise, do a per-capita\n",
    "                      plot (i.e., number of X per n people). If per_n is not 1,\n",
    "                      then population must be defined.\n",
    "    populations     - The dictionary of populations per state. Only necessary\n",
    "                      if per_n is greater than 1.\n",
    "    figsize         - The desired size of the plot.\n",
    "    legend_loc      - Desired location of the legend. The legend is\n",
    "                      only displayed if more than one plot type is\n",
    "                      set.\n",
    "    marker          - True to display a marker for each data point.\n",
    "                      False to suppress the marker.\n",
    "    trim_final_week - True to trim the final week; False otherwise.\n",
    "\n",
    "    NOTE: The final week of the CDC data is automatically trimmed\n",
    "    (unless trim_final_week is set to False), because experience\n",
    "    shows that it generally represents partial data, which skews the\n",
    "    graphs.\n",
    "    \"\"\"\n",
    "   \n",
    "    df2 = pd.concat([get_death_counts(df, s) for s in states])\n",
    "    column = PLOT_TYPE_COLUMNS[plot_type]\n",
    "\n",
    "    if per_n > 1:\n",
    "        df2[column] = df2.apply(\n",
    "            lambda row: get_per_capita_float(row[column], populations[row.state], per_n=per_n),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    # Since there's only one row for each date (per state), the group by\n",
    "    # isn't strictly necessary, but we have to call unstack(), and that's\n",
    "    # not going to work without a group by. sum() is effectively a no-op\n",
    "    # here.\n",
    "    to_plot = (\n",
    "        df2[['month_day', 'state', column]]\n",
    "            .groupby(['month_day', 'state'])\n",
    "            .sum()\n",
    "            .unstack()\n",
    "    )\n",
    "\n",
    "    fig, ax = p.subplots(figsize=figsize)\n",
    "    to_plot.plot(ax=ax, kind='line', legend=True, marker=('s' if marker else None))\n",
    "\n",
    "    ax.set_xlabel('Week\\n\\n(Source: CDC)')\n",
    "    label = PLOT_TYPE_LABELS[plot_type]\n",
    "    y_label = f\"{label}\"\n",
    "    if per_n > 1:\n",
    "        y_label = f\"{y_label} per {per_n:,}\"\n",
    "    ax.set_ylabel(y_label)\n",
    "\n",
    "    # If we're plotting cumulative deaths, display an info\n",
    "    # box showing the total deaths for each state. (It doesn't\n",
    "    # make sense to do this with weekly deaths.)\n",
    "    if plot_type == PlotType.CUMULATIVE_DEATHS:\n",
    "        heading = 'Total deaths' if per_n == 1 else f'Total deaths per {per_n:,}'\n",
    "        text_lines = [f'{heading}\\n']\n",
    "        for state in sorted(states):\n",
    "            total = int(round(df2.loc[df2.state == state][column].max()))\n",
    "            text_lines.append(f\"{state}: {total:,}\")\n",
    "        textbox(ax, 0.01, 0.99, '\\n'.join(text_lines))\n",
    "        if legend_loc == 'best':\n",
    "            legend_loc = 'upper center'\n",
    "\n",
    "    fix_pandas_multiplot_legend(ax, legend_loc)\n",
    "    if image_file is not None:\n",
    "        fig.savefig(os.path.join(IMAGES_PATH, image_file))\n",
    "\n",
    "    return (ax, fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Northeast states\n",
    "\n",
    "Data from some of the states that were hardest hit early on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_states = ('Connecticut', 'New York', 'New Jersey', 'Pennsylvania', 'Delaware', 'Ohio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deaths_for_many(df, ne_states, PlotType.CUMULATIVE_DEATHS, per_n=100_000, populations=populations,\n",
    "                     image_file='cdc-ne-states-cum-deaths.png', legend_loc='center left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deaths_for_many(df, ne_states, PlotType.WEEKLY_DEATHS, per_n=100_000, populations=populations,\n",
    "                     image_file='cdc-ne-states-weeklyl-deaths.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some of the bigger-hit states after the hurried reopenings\n",
    "\n",
    "- California\n",
    "- Arizona\n",
    "- Texas\n",
    "- Florida\n",
    "- Oklahoma\n",
    "- South Carolina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_sw_states = ('Arizona', 'Texas', 'Oklahoma', 'South Carolina', 'Utah', 'California', 'Florida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deaths_for_many(df, s_sw_states, PlotType.CUMULATIVE_DEATHS, per_n=100_000, populations=populations,\n",
    "                     image_file='cdc-s-sw-states-cum-deaths.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deaths_for_many(df, s_sw_states, PlotType.WEEKLY_DEATHS, per_n=100_000, populations=populations,\n",
    "                     image_file='cdc-s-sw-states-cum-deaths.png');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
